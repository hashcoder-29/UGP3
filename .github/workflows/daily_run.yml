# .github/workflows/daily_run.yml

name: Run Daily Data Pipeline

on:
  # This is the schedule trigger.
  # "30 10 * * *" is a CRON expression that means "at 10:30 UTC every day".
  # 10:30 UTC is 4:00 PM in India Standard Time (IST).
  schedule:
    - cron: "30 10 * * *"
  
  # This line allows you to manually run the workflow from the Actions tab on GitHub.
  workflow_dispatch:

jobs:
  build-and-run:
    runs-on: ubuntu-latest # The job will run on a fresh virtual machine

    steps:
      # Step 1: Check out your code from the repository
      - name: Checkout repository
        uses: actions/checkout@v3

      # Step 2: Set up the Conda environment
      - name: Set up Conda
        uses: conda-incubator/setup-miniconda@v2
        with:
          auto-update-conda: true
          python-version: 3.11
          environment-file: environment.yml # It will use your existing yml file
          activate-environment: nifty_pipeline

      # Step 3: Make the run script executable
      - name: Make script executable
        run: chmod +x ./run_pipeline.sh

      # Step 4: Run the main pipeline script
      - name: Run Data Pipeline
        env:
          # This section securely passes your GitHub secrets to the script
          # as environment variables.
          NEWS_API_KEY: ${{ secrets.NEWS_API_KEY }}
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: ./run_pipeline.sh